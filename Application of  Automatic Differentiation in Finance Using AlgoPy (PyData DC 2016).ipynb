{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of  Automatic Differentiation in Finance Using AlgoPy (PyData DC 2016)\n",
    "#####  Li Guo, Nicholas Liu, Nadia Udler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction of Automatic Differentiation Using Taylor Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation, or algorithmic differentiation (AD), is a set of techniques to evaluate the derivative of a function specified by a computer program. Fundamental to AD is the application of the chain rule for computing derivatives.\n",
    "\n",
    "<br>\n",
    "`AlgoPy` is a Python module for automatic differentiation. This tutorial shows how to calculate one-dimensional Taylor series expansion and partial derivatives of function by `AlgoPy`.\n",
    "\n",
    "<br>\n",
    "Recall Taylor expansion of an infinitely differentiable function to approximate function value $f(x)$ about a point a:\n",
    "\n",
    "<br>\n",
    "$$f(x)=f(a)+\\frac{f'(a)}{1!}(x-a)+\\frac{f''(a)}{2!}(x-a)^2+\\cdots=\\sum^{\\infty}_{n=0}\\frac{f^{(n)}(a)}{n!}(x-a)^n$$\n",
    "\n",
    "<br>\n",
    "For example, consider this function:\n",
    "$$f(x)=x^3+\\sin(2x)-e^{-x}$$\n",
    "\n",
    "<br>\n",
    "In this case we can compute derivatives analytically:\n",
    "\n",
    "<br>\n",
    "$$\\begin{align*} \n",
    "f'(x)&=3x^2+2\\cos(2x)+e^{-x} \\\\\n",
    "f''(x)&=6x-4\\sin(2x)-e^{-x} \\\\\n",
    "f^{(3)}(x)&=6x-8\\cos(2x)+e^{-x}\n",
    "\\end{align*}$$\n",
    "\n",
    "<br>\n",
    "For the above function, we can calculate the first 4 Taylor series expansion with $a=3$ and $x=3.5$ as below:\n",
    "\n",
    "<br>\n",
    "$$\\begin{align*} \n",
    "f(a)&=26.671 \\\\\n",
    "\\frac{f'(x)}{1!}(x-a)&=14.485 \\\\\n",
    "\\frac{f''(a)}{2!}(x-a)^2&=2.383 \\\\\n",
    "\\frac{f^{(3)}(a)}{3!}(x-a)^3&=-0.034\n",
    "\\end{align*}$$\n",
    "\n",
    "<br>\n",
    "With these derivatives we can easily approximate function value at any given x.\n",
    "\n",
    "<br>\n",
    "However, when target function is too complicated to be differentiated manually, we can use AD to get the coefficients. The code and result (same as in manually calculated example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.66707974e+01   1.44850638e+01   2.38348437e+00  -3.39911505e-02\n",
      "  -1.17719662e-02   8.01438444e-03   3.86996632e-04  -1.90432803e-04\n",
      "  -6.93477130e-06   2.64623988e-06]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from algopy import UTPM\n",
    "\n",
    "# Target function\n",
    "def f(x):\n",
    "    return (np.power(x, 3) + np.sin(2 * x) - np.exp(-x))\n",
    "\n",
    "D = 10                     # Number of coefficient parts (expansion parts)\n",
    "P = 1                      # Used to evaluate several Taylor at once, no effects here\n",
    "x = UTPM(np.zeros((D, P))) # UTPM stands for Univariate Taylor Polynomial of Matrices\n",
    "x.data[0, 0] = 3           # a = 3\n",
    "x.data[1, 0] = 0.5         # x - a = 0.5\n",
    "y=f(x)\n",
    "print(y.data[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Prices and Sensitivities of European Option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at computing gradient vector, Hessian matrix and Jacobian matrix with `AlgoPy`. These are used in quantitative finance field frequently. \n",
    "\n",
    "<br>\n",
    "Suppose the target function is multidimensional ${\\rm I\\!R}^n\\rightarrow{\\rm I\\!R}$. We would like to compute partial derivatives of first and second order. In many cases it is difficult to compute analytical derivatives of the function (the analytical form of the function is not available , or too complicated). Then  AD  can be used to compute gradient vector, Jacobian and Hessian matrices of the function.\n",
    "\n",
    "<br>\n",
    "As an example we look at  Black-Scholes (BS) Formula for pricing European call option on stock. This  contracts give the owner the right, but not the obligation, to buy the underlying security at a specific price, known as the strike price ($K$), on the option's expiration date (time $T$). The below expression gives the price ($C$) of the contract, where $\\sigma$ is volatility of the underlying, $S$ is the current price of the underlying, and $r$ is a risk free rate.\n",
    "\n",
    "<br>\n",
    "$$\\begin{align*} \n",
    "C(S, \\sigma, T, r)&=SN(d_1)+Ke^{-rT}N(d_2) \\\\\n",
    "d_1&=\\dfrac{\\ln(\\dfrac{S}{K})+(r+\\dfrac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}} \\\\\n",
    "d_2&=d_1-\\sigma\\sqrt{T}\n",
    "\\end{align*}$$\n",
    "\n",
    "<br>\n",
    "First-order sensitivities:\n",
    "\n",
    "<br>\n",
    "$$delta=\\frac{\\partial C}{\\partial S} \\qquad vega=\\frac{\\partial C}{\\partial \\sigma} \\qquad theta=\\frac{\\partial C}{\\partial T} \\qquad rho=\\frac{\\partial C}{\\partial r}$$\n",
    "\n",
    "<br>\n",
    "Second-order sensitivities:\n",
    "\n",
    "<br>\n",
    "$$\\begin{align*}\n",
    "gamma=\\frac{\\partial^2 C}{\\partial S^2} \\qquad vanna&=\\frac{\\partial^2 C}{\\partial S\\partial \\sigma} \\qquad vomma=\\frac{\\partial^2 C}{\\partial \\sigma^2} \\\\\n",
    "\\\\\n",
    "charm=-\\frac{\\partial^2 C}{\\partial T \\partial S} \\qquad veta&=\\frac{\\partial^2 C}{\\partial \\sigma \\partial T} \\qquad vera=\\frac{\\partial^2 C}{\\partial \\sigma \\partial r}\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "<br>\n",
    "Then we calculate gradient vector and Hessian matrix of the BS function with `AlgoPy`.The sensitivities computed above will be the elements of the gradient and Hessian. For this purpose we define BS function as a Python function and call the `AlgoPy` to find  gradient and Hessian. \n",
    "One obstacle we encounter when applying AD to BS function in Python: BS function would be calling built-in function (`.norm.cdf(x)` from `scipy`), that computes cumulative normal distribution `N(x)`. However, AD cannot be applied to built-in functions (chain rule cannot be applied to the function if it cannot be accessed) . We use our version of normal cds function (algorithms is available from many sources, for example see Numerical methods in C by Press, Teukolsky et al)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from algopy import UTPM\n",
    "\n",
    "def erf(x):\n",
    "    \"\"\"Complementary error function\"\"\"\n",
    "    z = abs(x)\n",
    "    t = 1 / (1 + 0.5 * z)\n",
    "    r = t * exp(-z*z-1.26551223+t*(1.00002368+t*(.37409196+\n",
    "        t*(.09678418+t*(-.18628806+t*(.27886807+\n",
    "        t*(-1.13520398+t*(1.48851587+t*(-.82215223+\n",
    "        t*.17087277)))))))))\n",
    "    if (x >= 0):\n",
    "        return r\n",
    "    else:\n",
    "        return 2 - r\n",
    "    \n",
    "def N(x):\n",
    "    \"\"\"Normal cumulative density function\"\"\"\n",
    "    return 1 - 0.5 * erf(x / (2 ** 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function C computes a price of European call option, where the input x is a vector of $[S,\\sigma,T,r]$ and strike price equals 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def C(x):\n",
    "    K, S, sigma, T, r = 10, x[0], x[1], x[2], x[3]\n",
    "    d1 = (log(S / K) + (r + power(sigma, 2) / 2)) / (sigma * sqrt(T))\n",
    "    d2 = d1 - x[1] * sqrt(x[2])\n",
    "    return S * N(d1) - K * exp(-r * T) * N(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian matrix (also the gradient) in our case is\n",
    "\n",
    "<br>\n",
    "$$\\begin{bmatrix}\n",
    "\\dfrac{\\partial C}{\\partial S} &\\dfrac{\\partial C}{\\partial \\sigma} &\\dfrac{\\partial C}{\\partial T} &\\dfrac{\\partial C}{\\partial r}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "The code to calculate Jacobian matrix is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-order Greeks:\n",
      " [ 0.87730282  2.43829855  0.48601709  8.07291282]\n"
     ]
    }
   ],
   "source": [
    "x = UTPM.init_jacobian([12, 0.2, 1, 0.03]) # S=12, Ïƒ=0.2, T=1, r=0.03\n",
    "y = C(x)\n",
    "J = UTPM.extract_jacobian(y)\n",
    "print('First-order Greeks:\\n', J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian matrix in our case is\n",
    "\n",
    "<br>\n",
    "$$\\begin{bmatrix}\n",
    "    \\dfrac{\\partial^2 C}{\\partial S^2} &\\dfrac{\\partial^2 C}{\\partial \\sigma \\partial S} &\\dfrac{\\partial^2 C}{\\partial T \\partial S} &\\dfrac{\\partial^2 C}{\\partial r \\partial S} \\\\\n",
    "    \\dfrac{\\partial^2 C}{\\partial S \\partial \\sigma}&\\dfrac{\\partial^2 C}{\\partial \\sigma^2} &\\dfrac{\\partial^2 C}{\\partial T \\partial \\sigma} &\\dfrac{\\partial^2 C}{\\partial r \\partial \\sigma} \\\\\n",
    "    \\dfrac{\\partial^2 C}{\\partial S \\partial T} &\\dfrac{\\partial^2 C}{\\partial \\sigma \\partial T} &\\dfrac{\\partial^2 C}{\\partial T^2} &\\dfrac{\\partial^2 C}{\\partial r \\partial T} \\\\\n",
    "    \\dfrac{\\partial^2 C}{\\partial S \\partial r} &\\dfrac{\\partial^2 C}{\\partial \\sigma \\partial r} &\\dfrac{\\partial^2 C}{\\partial T \\partial r} &\\dfrac{\\partial^2 C}{\\partial r^2}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "<br>\n",
    "The code to calculate Hessian matrix is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian matrix and second-order Greeks:\n",
      " [[  0.19340522  -0.09682358   0.04830366   1.93405216]\n",
      " [ -0.09682358   0.24204836   1.81257802  -4.8349186 ]\n",
      " [  0.04830366   1.81257802  -0.25537928   4.99071985]\n",
      " [  1.93405216  -4.8349186    4.99071985  14.29480367]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\algopy\\utpm\\utpm.py:1798: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  S = numpy.zeros((N,M), dtype=x.dtype)\n"
     ]
    }
   ],
   "source": [
    "x = UTPM.init_hessian([10, 0.2, 1, 0.03]) # S=10, Ïƒ=0.2, T=1, r=0.03\n",
    "y = C(x)\n",
    "H = UTPM.extract_hessian(4, y) # H is of size 4 by 4\n",
    "print('Hessian matrix and second-order Greeks:\\n', H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with Closed-Form Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of checking these results is to use the theoretical derivation of Greeks from Black-Scholes-Merton model. See closed-form formula of Greeks [here](https://en.wikipedia.org/wiki/Blackâ€“Scholes_model#The_Greeks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking First-Order Greeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider computing the derivative of option price with respect to the underlying asset's price, i.e., $delta$: its closed form is just the normal cumulative distribution function $N(d_1)$, where $d_1=\\dfrac{\\ln(\\dfrac{S}{K})+(r+\\dfrac{\\sigma^2}{2})T}{\\sigma\\sqrt{T}}$. We can use built-in normal cumulative density function  from `SciPy` to calculate closed-form $delta$ as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-form delta using scipy.stats.norm is:\n",
      " 0.877302590601\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "K, S, sigma, T, r = 10, 12, 0.2, 1, 0.03\n",
    "d1 = (log(S / K) + (r + power(sigma, 2) / 2)) / (sigma * sqrt(T))\n",
    "print(\"Closed-form delta using scipy.stats.norm is:\\n\", norm.cdf(d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can use our own normal cumulative density function `N(x)` to check our result. The result is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-form delta using N(x) is:\n",
      " 0.877302582172\n"
     ]
    }
   ],
   "source": [
    "print(\"Closed-form delta using N(x) is:\\n\", N(d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the above two $delta$ values are almost the same as what we get from automatic differentiation, see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta calculated using AD is:\n",
      " 0.877302823318\n"
     ]
    }
   ],
   "source": [
    "print(\"Delta calculated using AD is:\\n\", J[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Second-Order Greeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take $charm$ of call option as an example. It is a rate of change of $delta$ over time. Its closed form is $-\\phi(d_1)\\dfrac{2rT-d_2\\sigma\\sqrt{T}}{2T\\sigma\\sqrt{T}}$, where $\\phi(x)$ denotes the standard normal probability density function, i.e., $\\dfrac{1}{2\\sqrt{\\pi}}e^{-\\frac{x^2}{2}}$, and $d_2 = d_1-\\sigma\\sqrt{T}$.\n",
    "\n",
    "<br>\n",
    "We use built-in normal probability density function from `SciPy` to calculate closed-form $charm$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed-form charm using scipy.stats.norm is:\n",
      " -0.0483335146004\n"
     ]
    }
   ],
   "source": [
    "K, S, sigma, T, r = 10, 10, 0.2, 1, 0.03\n",
    "d1 = (log(S / K) + (r + power(sigma, 2) / 2)) / (sigma * sqrt(T))\n",
    "d2 = d1 - sigma * sqrt(T)\n",
    "charm = -norm.pdf(d1) * (2 * r * T - d2 * sigma * sqrt(T)) / (2 * T * sigma * sqrt(T))\n",
    "print(\"Closed-form charm using scipy.stats.norm is:\\n\", charm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the closed-form result is pretty close to the result obtained from AD,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charm calculated using AD is:\n",
      " -0.0483036618516\n"
     ]
    }
   ],
   "source": [
    "# Be cautious of the minus sign in the definition of charm\n",
    "print(\"Charm calculated using AD is:\\n\", -H[0][2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our tutorial. For more information and a general tutorial of `AlgoPy`, check its official website at https://pythonhosted.org/algopy/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
